{
  "hash": "30a7fb3cd06ec71a2c29ea50813b6311",
  "result": {
    "markdown": "---\nexecute:\n  output: true\ntitle: Performance Benchmarks\n---\n\n\n\n\n```@meta\nCurrentModule = CounterfactualExplanations \n```\n\n\n\n\nIn the previous tutorial, we have seen how counterfactual explanations can be evaluated. An important follow-up task is to compare the performance of different counterfactual generators is an important task. Researchers can use benchmarks to test new ideas they want to implement. Practitioners can find the right counterfactual generator for their specific use case through benchmarks. In this tutorial, we will see how to run benchmarks for counterfactual generators. \n\n## Post Hoc Benchmarking\n\nWe begin by continuing the discussion from the previous tutorial: suppose you have generated multiple counterfactual explanations for multiple individuals, like below:\n\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\n# Factual and target:\nn_individuals = 5\nids = rand(findall(predict_label(M, counterfactual_data) .== factual), n_individuals)\nxs = select_factual(counterfactual_data, ids)\nces = generate_counterfactual(xs, target, counterfactual_data, M, generator; num_counterfactuals=5)\n```\n:::\n\n\nYou may be interested in comparing the outcomes across individuals. To benchmark the various counterfactual explanations using default evaluation measures, you can simply proceed as follows:\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nbmk = benchmark(ces)\n```\n:::\n\n\nUnder the hood, the [`benchmark(counterfactual_explanations::Vector{CounterfactualExplanation})`](@ref) uses [`evaluate(counterfactual_explanations::Vector{CounterfactualExplanation})`](@ref) to generate a [`Benchmark`](@ref) object, which contains the evaluation in its most granular form as a `DataFrame`.\n\n### Working with `Benchmark`s\n\nFor convenience, the `DataFrame` containing the evaluation can be returned by simply calling the `Benchmark` object. By default, the aggregated evaluation measures across `id` (in line with the default behaviour of `evaluate`).\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\nbmk()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n\\begin{tabular}{r|ccccc}\n\t& sample & variable & value & generator & \\\\\n\t\\hline\n\t& Int64 & String & Float64 & Symbol & \\\\\n\t\\hline\n\t1 & 1 & distance & 0.560887 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t2 & 1 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t3 & 1 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t4 & 2 & distance & 1.03898 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t5 & 2 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t6 & 2 & validity & 0.8 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t7 & 3 & distance & 0.326338 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t8 & 3 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t9 & 3 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t10 & 4 & distance & 1.5446 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t11 & 4 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t12 & 4 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t13 & 5 & distance & 0.600052 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t14 & 5 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t15 & 5 & validity & 0.8 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n::: {.cell execution_count=5}\n\n::: {.cell-output .cell-output-stdout}\n```\n15×7 DataFrame\n Row │ sample  variable    value     generator                          model  ⋯\n     │ Int64   String      Float64   Symbol                             Symbol ⋯\n─────┼──────────────────────────────────────────────────────────────────────────\n   1 │      1  distance    0.560887  GradientBasedGenerator(nothing, …  FluxMo ⋯\n   2 │      1  redundancy  0.0       GradientBasedGenerator(nothing, …  FluxMo\n   3 │      1  validity    1.0       GradientBasedGenerator(nothing, …  FluxMo\n   4 │      2  distance    1.03898   GradientBasedGenerator(nothing, …  FluxMo\n   5 │      2  redundancy  0.0       GradientBasedGenerator(nothing, …  FluxMo ⋯\n   6 │      2  validity    0.8       GradientBasedGenerator(nothing, …  FluxMo\n   7 │      3  distance    0.326338  GradientBasedGenerator(nothing, …  FluxMo\n   8 │      3  redundancy  0.0       GradientBasedGenerator(nothing, …  FluxMo\n   9 │      3  validity    1.0       GradientBasedGenerator(nothing, …  FluxMo ⋯\n  10 │      4  distance    1.5446    GradientBasedGenerator(nothing, …  FluxMo\n  11 │      4  redundancy  0.0       GradientBasedGenerator(nothing, …  FluxMo\n  12 │      4  validity    1.0       GradientBasedGenerator(nothing, …  FluxMo\n  13 │      5  distance    0.600052  GradientBasedGenerator(nothing, …  FluxMo ⋯\n  14 │      5  redundancy  0.0       GradientBasedGenerator(nothing, …  FluxMo\n  15 │      5  validity    0.8       GradientBasedGenerator(nothing, …  FluxMo\n                                                               3 columns omitted\n```\n:::\n:::\n\n\nTo retrieve the granular dataset, simply do:\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\nbmk(agg=nothing)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n\\begin{tabular}{r|cccccc}\n\t& sample & num\\_counterfactual & variable & value & generator & \\\\\n\t\\hline\n\t& Int64 & Int64 & String & Float64 & Symbol & \\\\\n\t\\hline\n\t1 & 1 & 1 & distance & 0.562579 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t2 & 1 & 2 & distance & 0.576755 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t3 & 1 & 3 & distance & 0.530911 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t4 & 1 & 4 & distance & 0.505757 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t5 & 1 & 5 & distance & 0.628436 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t6 & 1 & 1 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t7 & 1 & 2 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t8 & 1 & 3 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t9 & 1 & 4 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t10 & 1 & 5 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t11 & 1 & 1 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t12 & 1 & 2 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t13 & 1 & 3 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t14 & 1 & 4 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t15 & 1 & 5 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t16 & 2 & 1 & distance & 1.10954 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t17 & 2 & 2 & distance & 0.93087 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t18 & 2 & 3 & distance & 1.01782 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t19 & 2 & 4 & distance & 1.13205 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t20 & 2 & 5 & distance & 1.00461 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t21 & 2 & 1 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t22 & 2 & 2 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t23 & 2 & 3 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t24 & 2 & 4 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t25 & 2 & 5 & redundancy & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t26 & 2 & 1 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t27 & 2 & 2 & validity & 0.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t28 & 2 & 3 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t29 & 2 & 4 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t30 & 2 & 5 & validity & 1.0 & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) & $\\dots$ \\\\\n\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n::: {.cell execution_count=7}\n\n::: {.cell-output .cell-output-stdout}\n```\n75×8 DataFrame\n Row │ sample  num_counterfactual  variable    value     generator             ⋯\n     │ Int64   Int64               String      Float64   Symbol                ⋯\n─────┼──────────────────────────────────────────────────────────────────────────\n   1 │      1                   1  distance    0.562579  GradientBasedGenerato ⋯\n   2 │      1                   2  distance    0.576755  GradientBasedGenerato\n   3 │      1                   3  distance    0.530911  GradientBasedGenerato\n   4 │      1                   4  distance    0.505757  GradientBasedGenerato\n   5 │      1                   5  distance    0.628436  GradientBasedGenerato ⋯\n   6 │      1                   1  redundancy  0.0       GradientBasedGenerato\n   7 │      1                   2  redundancy  0.0       GradientBasedGenerato\n   8 │      1                   3  redundancy  0.0       GradientBasedGenerato\n   9 │      1                   4  redundancy  0.0       GradientBasedGenerato ⋯\n  10 │      1                   5  redundancy  0.0       GradientBasedGenerato\n  11 │      1                   1  validity    1.0       GradientBasedGenerato\n  ⋮  │   ⋮             ⋮               ⋮          ⋮                      ⋮     ⋱\n  66 │      5                   1  redundancy  0.0       GradientBasedGenerato\n  67 │      5                   2  redundancy  0.0       GradientBasedGenerato ⋯\n  68 │      5                   3  redundancy  0.0       GradientBasedGenerato\n  69 │      5                   4  redundancy  0.0       GradientBasedGenerato\n  70 │      5                   5  redundancy  0.0       GradientBasedGenerato\n  71 │      5                   1  validity    1.0       GradientBasedGenerato ⋯\n  72 │      5                   2  validity    1.0       GradientBasedGenerato\n  73 │      5                   3  validity    0.0       GradientBasedGenerato\n  74 │      5                   4  validity    1.0       GradientBasedGenerato\n  75 │      5                   5  validity    1.0       GradientBasedGenerato ⋯\n                                                   4 columns and 54 rows omitted\n```\n:::\n:::\n\n\nSince benchmarks return a `DataFrame` object on call, post-processing is straightforward. For example, we could use [`Tidier.jl`](https://kdpsingh.github.io/Tidier.jl/dev/):\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\nusing Tidier\n@chain bmk() begin\n    @filter(variable == \"distance\")\n    @select(sample, variable, value)\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n\\begin{tabular}{r|ccc}\n\t& sample & variable & value\\\\\n\t\\hline\n\t& Int64 & String & Float64\\\\\n\t\\hline\n\t1 & 1 & distance & 0.560887 \\\\\n\t2 & 2 & distance & 1.03898 \\\\\n\t3 & 3 & distance & 0.326338 \\\\\n\t4 & 4 & distance & 1.5446 \\\\\n\t5 & 5 & distance & 0.600052 \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n::: {.cell execution_count=9}\n\n::: {.cell-output .cell-output-stdout}\n```\n5×3 DataFrame\n Row │ sample  variable  value    \n     │ Int64   String    Float64  \n─────┼────────────────────────────\n   1 │      1  distance  0.560887\n   2 │      2  distance  1.03898\n   3 │      3  distance  0.326338\n   4 │      4  distance  1.5446\n   5 │      5  distance  0.600052\n```\n:::\n:::\n\n\n### Metadata for Counterfactual Explanations\n\nBenchmarks always report metadata for each counterfactual explanation, which is automatically inferred by default. The default metadata concerns the explained `model` and the employed `generator`. In the current example, we used the same model and generator for each individual:\n\n::: {.cell execution_count=10}\n``` {.julia .cell-code}\n@chain bmk() begin\n    @group_by(sample)\n    @select(sample, model, generator)\n    @summarize(model=unique(model),generator=unique(generator))\n    @ungroup\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n\\begin{tabular}{r|ccc}\n\t& sample & model & generator\\\\\n\t\\hline\n\t& Int64 & Symbol & Symbol\\\\\n\t\\hline\n\t1 & 1 & FluxModel(Chain(Dense(2 => 2)), :classification\\_multi) & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) \\\\\n\t2 & 2 & FluxModel(Chain(Dense(2 => 2)), :classification\\_multi) & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) \\\\\n\t3 & 3 & FluxModel(Chain(Dense(2 => 2)), :classification\\_multi) & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) \\\\\n\t4 & 4 & FluxModel(Chain(Dense(2 => 2)), :classification\\_multi) & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) \\\\\n\t5 & 5 & FluxModel(Chain(Dense(2 => 2)), :classification\\_multi) & GradientBasedGenerator(nothing, CounterfactualExplanations.Objectives.distance\\_l1, 0.1, false, Descent(0.1)) \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n::: {.cell execution_count=11}\n\n::: {.cell-output .cell-output-stdout}\n```\n5×3 DataFrame\n Row │ sample  model                              generator                    ⋯\n     │ Int64   Symbol                             Symbol                       ⋯\n─────┼──────────────────────────────────────────────────────────────────────────\n   1 │      1  FluxModel(Chain(Dense(2 => 2)), …  GradientBasedGenerator(nothi ⋯\n   2 │      2  FluxModel(Chain(Dense(2 => 2)), …  GradientBasedGenerator(nothi\n   3 │      3  FluxModel(Chain(Dense(2 => 2)), …  GradientBasedGenerator(nothi\n   4 │      4  FluxModel(Chain(Dense(2 => 2)), …  GradientBasedGenerator(nothi\n   5 │      5  FluxModel(Chain(Dense(2 => 2)), …  GradientBasedGenerator(nothi ⋯\n                                                                1 column omitted\n```\n:::\n:::\n\n\nMetadata can also be provided as an optional key argument.\n\n::: {.cell execution_count=12}\n``` {.julia .cell-code}\nmeta_data = Dict(\n    :generator => \"Generic\",\n    :model => \"MLP\",\n)\nmeta_data = [meta_data for i in 1:length(ces)]\nbmk = benchmark(ces; meta_data=meta_data)\n@chain bmk() begin\n    @group_by(sample)\n    @select(sample, model, generator)\n    @summarize(model=unique(model),generator=unique(generator))\n    @ungroup\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n\\begin{tabular}{r|ccc}\n\t& sample & model & generator\\\\\n\t\\hline\n\t& Int64 & String & String\\\\\n\t\\hline\n\t1 & 1 & MLP & Generic \\\\\n\t2 & 2 & MLP & Generic \\\\\n\t3 & 3 & MLP & Generic \\\\\n\t4 & 4 & MLP & Generic \\\\\n\t5 & 5 & MLP & Generic \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n::: {.cell execution_count=13}\n\n::: {.cell-output .cell-output-stdout}\n```\n5×3 DataFrame\n Row │ sample  model   generator \n     │ Int64   String  String    \n─────┼───────────────────────────\n   1 │      1  MLP     Generic\n   2 │      2  MLP     Generic\n   3 │      3  MLP     Generic\n   4 │      4  MLP     Generic\n   5 │      5  MLP     Generic\n```\n:::\n:::\n\n\n## Ad Hoc Benchmarking\n\nSo far we have assumed the following workflow:\n\n1. Fit some machine learning model.\n2. Generate counterfactual explanations for some individual(s) (`generate_counterfactual`).\n3. Evaluate and benchmark them (`benchmark(ces::Vector{CounterfactualExplanation})`).\n\nIn many cases, it may be preferable to combine these steps. To this end, we have added support for two scenarios of Ad Hoc Benchmarking.\n\n### Pre-trained Models\n\nIn the first scenario, it is assumed that the machine learning models have been pre-trained and so the workflow can be summarized as follows:\n\n1. Fit some machine learning model(s).\n2. Generate counterfactual explanations and benchmark them. \n\nWe suspect that this is the most common workflow for practitioners who are interested in benchmarking counterfactual explanations for the pre-trained machine learning models. Let's go through this workflow using a simple example. We first train some models and store them in a dictionary:\n\n::: {.cell execution_count=14}\n``` {.julia .cell-code}\nmodels = Dict(\n    :MLP => fit_model(counterfactual_data, :MLP),\n    :Linear => fit_model(counterfactual_data, :Linear),\n)\n```\n:::\n\n\nNext, we store the counterfactual generators of interest in a dictionary as well:\n\n::: {.cell execution_count=15}\n``` {.julia .cell-code}\ngenerators = Dict(\n    :Generic => GenericGenerator(),\n    :Gravitational => GravitationalGenerator(),\n    :Wachter => WachterGenerator(),\n    :ClaPROAR => ClaPROARGenerator(),\n)\n```\n:::\n\n\nThen we can run a benchmark for individual(s) `x`, a pre-specified `target` and `counterfactual_data` as follows:\n\n::: {.cell execution_count=16}\n``` {.julia .cell-code}\nbmk = benchmark(x, target, counterfactual_data; models=models, generators=generators)\n```\n:::\n\n\nIn this case, metadata is automatically inferred from the dictionaries:\n\n::: {.cell execution_count=17}\n``` {.julia .cell-code}\n@chain bmk() begin\n    @filter(variable == \"distance\")\n    @select(sample, variable, value, model, generator)\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n\\begin{tabular}{r|ccccc}\n\t& sample & variable & value & model & generator\\\\\n\t\\hline\n\t& Int64 & String & Float64 & Symbol & Symbol\\\\\n\t\\hline\n\t1 & 1 & distance & 0.346822 & Linear & Gravitational \\\\\n\t2 & 1 & distance & 0.45062 & Linear & ClaPROAR \\\\\n\t3 & 1 & distance & 0.42487 & Linear & Generic \\\\\n\t4 & 1 & distance & 0.486442 & Linear & Wachter \\\\\n\t5 & 1 & distance & 0.687121 & MLP & Gravitational \\\\\n\t6 & 1 & distance & 0.728272 & MLP & ClaPROAR \\\\\n\t7 & 1 & distance & 0.57091 & MLP & Generic \\\\\n\t8 & 1 & distance & 0.711715 & MLP & Wachter \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n::: {.cell execution_count=18}\n\n::: {.cell-output .cell-output-stdout}\n```\n8×5 DataFrame\n Row │ sample  variable  value     model   generator     \n     │ Int64   String    Float64   Symbol  Symbol        \n─────┼───────────────────────────────────────────────────\n   1 │      1  distance  0.346822  Linear  Gravitational\n   2 │      1  distance  0.45062   Linear  ClaPROAR\n   3 │      1  distance  0.42487   Linear  Generic\n   4 │      1  distance  0.486442  Linear  Wachter\n   5 │      1  distance  0.687121  MLP     Gravitational\n   6 │      1  distance  0.728272  MLP     ClaPROAR\n   7 │      1  distance  0.57091   MLP     Generic\n   8 │      1  distance  0.711715  MLP     Wachter\n```\n:::\n:::\n\n\n### Everything at once\n\nResearchers, in particular, may be interested in combining all steps into one. This is the second scenario of Ad Hoc Benchmarking:\n\n1. Fit some machine learning model(s), generate counterfactual explanations and benchmark them. \n\nIt involves calling `benchmark` directly on counterfactual data (the only positional argument):\n\n::: {.cell execution_count=19}\n``` {.julia .cell-code}\nbmk = benchmark(counterfactual_data)\n```\n:::\n\n\nThis will use the default models from [`standard_models_catalogue`](@ref) and train them on the data. All available generators from [`generator_catalogue`](@ref) will also be used:\n\n::: {.cell execution_count=20}\n``` {.julia .cell-code}\n@chain bmk() begin\n    @filter(variable == \"validity\")\n    @select(sample, variable, value, model, generator)\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n\\begin{tabular}{r|ccccc}\n\t& sample & variable & value & model & generator\\\\\n\t\\hline\n\t& Int64 & String & Float64 & Symbol & Symbol\\\\\n\t\\hline\n\t1 & 1 & validity & 1.0 & Linear & gravitational \\\\\n\t2 & 2 & validity & 1.0 & Linear & gravitational \\\\\n\t3 & 3 & validity & 1.0 & Linear & gravitational \\\\\n\t4 & 4 & validity & 1.0 & Linear & gravitational \\\\\n\t5 & 5 & validity & 1.0 & Linear & gravitational \\\\\n\t6 & 1 & validity & 1.0 & Linear & growing\\_spheres \\\\\n\t7 & 2 & validity & 1.0 & Linear & growing\\_spheres \\\\\n\t8 & 3 & validity & 1.0 & Linear & growing\\_spheres \\\\\n\t9 & 4 & validity & 1.0 & Linear & growing\\_spheres \\\\\n\t10 & 5 & validity & 1.0 & Linear & growing\\_spheres \\\\\n\t11 & 1 & validity & 1.0 & Linear & revise \\\\\n\t12 & 2 & validity & 1.0 & Linear & revise \\\\\n\t13 & 3 & validity & 1.0 & Linear & revise \\\\\n\t14 & 4 & validity & 1.0 & Linear & revise \\\\\n\t15 & 5 & validity & 1.0 & Linear & revise \\\\\n\t16 & 1 & validity & 1.0 & Linear & clue \\\\\n\t17 & 2 & validity & 0.0 & Linear & clue \\\\\n\t18 & 3 & validity & 1.0 & Linear & clue \\\\\n\t19 & 4 & validity & 0.0 & Linear & clue \\\\\n\t20 & 5 & validity & 0.0 & Linear & clue \\\\\n\t21 & 1 & validity & 0.0 & Linear & probe \\\\\n\t22 & 2 & validity & 0.0 & Linear & probe \\\\\n\t23 & 3 & validity & 0.0 & Linear & probe \\\\\n\t24 & 4 & validity & 0.0 & Linear & probe \\\\\n\t25 & 5 & validity & 0.0 & Linear & probe \\\\\n\t26 & 1 & validity & 1.0 & Linear & dice \\\\\n\t27 & 2 & validity & 1.0 & Linear & dice \\\\\n\t28 & 3 & validity & 1.0 & Linear & dice \\\\\n\t29 & 4 & validity & 1.0 & Linear & dice \\\\\n\t30 & 5 & validity & 1.0 & Linear & dice \\\\\n\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n::: {.cell execution_count=21}\n\n::: {.cell-output .cell-output-stdout}\n```\n165×5 DataFrame\n Row │ sample  variable  value    model   generator       \n     │ Int64   String    Float64  Symbol  Symbol          \n─────┼────────────────────────────────────────────────────\n   1 │      1  validity      1.0  Linear  gravitational\n   2 │      2  validity      1.0  Linear  gravitational\n   3 │      3  validity      1.0  Linear  gravitational\n   4 │      4  validity      1.0  Linear  gravitational\n   5 │      5  validity      1.0  Linear  gravitational\n   6 │      1  validity      1.0  Linear  growing_spheres\n   7 │      2  validity      1.0  Linear  growing_spheres\n   8 │      3  validity      1.0  Linear  growing_spheres\n   9 │      4  validity      1.0  Linear  growing_spheres\n  10 │      5  validity      1.0  Linear  growing_spheres\n  11 │      1  validity      1.0  Linear  revise\n  ⋮  │   ⋮        ⋮         ⋮       ⋮            ⋮\n 156 │     11  validity      1.0  MLP     generic\n 157 │     12  validity      1.0  MLP     generic\n 158 │     13  validity      1.0  MLP     generic\n 159 │     14  validity      0.0  MLP     generic\n 160 │     15  validity      1.0  MLP     generic\n 161 │     11  validity      0.0  MLP     greedy\n 162 │     12  validity      1.0  MLP     greedy\n 163 │     13  validity      1.0  MLP     greedy\n 164 │     14  validity      0.0  MLP     greedy\n 165 │     15  validity      1.0  MLP     greedy\n                                          144 rows omitted\n```\n:::\n:::\n\n\nOptionally, you can instead provide a dictionary of `models` and `generators` as before. Each value in the `models` dictionary should be one of two things:\n\na. Either be an object `M` of type [`AbstractFittedModel`](@ref) that implements the [`Models.train`](@ref) method.\nb. Or a `DataType` that can be called on [`CounterfactualData`](@ref) to create an object `M` as in (a).\n\n## Multiple Datasets\n\nBenchmarks are run on single instances of type [`CounterfactualData`](@ref). This is our design choice for two reasons:\n\n1. We want to avoid the loops inside the `benchmark` method(s) from getting too nested and convoluted. \n2. While it is straightforward to infer metadata for models and generators, this is not the case for datasets. \n\nFortunately, it is very easy to run benchmarks for multiple datasets anyway, since `Benchmark` instances can be concatenated. To see how, let's consider an example involving multiple datasets, models and generators:\n\n::: {.cell execution_count=22}\n``` {.julia .cell-code}\n# Data:\ndatasets = Dict(\n    :moons => load_moons(),\n    :circles => load_circles(),\n)\n\n# Models:\nmodels = Dict(\n    :MLP => FluxModel,\n    :Linear => Linear,\n)\n\n# Generators:\ngenerators = Dict(\n    :Generic => GenericGenerator(),\n    :Greedy => GreedyGenerator(),\n)\n```\n:::\n\n\nThen we can simply loop over the datasets and eventually concatenate the results like so:\n\n::: {.cell execution_count=23}\n``` {.julia .cell-code}\nusing CounterfactualExplanations.Evaluation: distance_measures\nbmks = []\nfor (dataname, dataset) in datasets\n    bmk = benchmark(dataset; models=models, generators=generators, measure=distance_measures, verbose=true)\n    push!(bmks, bmk)\nend\nbmk = vcat(bmks[1], bmks[2]; ids=collect(keys(datasets)))\n```\n:::\n\n\nWhen `ids` are supplied, then a new id column is added to the evaluation data frame that contains unique identifiers for the different benchmarks. The optional `idcol_name` argument can be used to specify the name for that indicator column (defaults to `\"dataset\"`):\n\n::: {.cell execution_count=24}\n``` {.julia .cell-code}\n@chain bmk() begin\n    @group_by(dataset, generator)\n    @filter(model == :MLP)\n    @filter(variable == \"distance_l1\")\n    @summarize(L1_norm=mean(value))\n    @ungroup\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n\\begin{tabular}{r|ccc}\n\t& dataset & generator & L1\\_norm\\\\\n\t\\hline\n\t& Symbol & Symbol & Float32\\\\\n\t\\hline\n\t1 & circles & Generic & 1.88603 \\\\\n\t2 & circles & Greedy & 0.66296 \\\\\n\t3 & moons & Generic & 0.787587 \\\\\n\t4 & moons & Greedy & 0.612045 \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n::: {.cell execution_count=25}\n\n::: {.cell-output .cell-output-stdout}\n```\n4×3 DataFrame\n Row │ dataset  generator  L1_norm  \n     │ Symbol   Symbol     Float32  \n─────┼──────────────────────────────\n   1 │ circles  Generic    1.88603\n   2 │ circles  Greedy     0.66296\n   3 │ moons    Generic    0.787587\n   4 │ moons    Greedy     0.612045\n```\n:::\n:::\n\n\n",
    "supporting": [
      "benchmarking_files"
    ],
    "filters": []
  }
}