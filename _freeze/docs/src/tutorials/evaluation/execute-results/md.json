{
  "hash": "167bb633af45dfff3e2d0f3ceb017c45",
  "result": {
    "markdown": "---\nexecute:\n  output: true\ntitle: Performance Evaluation\n---\n\n\n\n\n```@meta\nCurrentModule = CounterfactualExplanations \n```\n\n\n\n\nNow that we know how to generate counterfactual explanations in Julia, you may have a few follow-up questions: How do I know if the counterfactual search has been successful? How good is my counterfactual explanation? What does 'good' even mean in this context? In this tutorial, we will see how counterfactual explanations can be evaluated with respect to their performance.\n\n## Default Measures\n\nNumerous evaluation measures for counterfactual explanations have been proposed. In what follows, we will cover some of the most important measures.\n\n### Single Measure, Single Counterfactual\n\nOne of the most important measures is [`validity`](@ref), which simply determines whether or not a counterfactual explanation $x^{\\prime}$ is valid in the sense that it yields the target prediction: $M(x^{\\prime})=t$. We can evaluate the validity of a single counterfactual explanation `ce` using the [`Evaluation.evaluate`](@ref) function as follows:\n\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\nusing CounterfactualExplanations.Evaluation: evaluate, validity\nevaluate(ce; measure=validity)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n1-element Vector{Vector{Float64}}:\n [1.0]\n```\n:::\n:::\n\n\nFor a single counterfactual explanation, this evaluation measure can only take two values: it is either equal to `1`, if the explanation is valid or `0` otherwise. Another important measure is [`distance`](@ref), which relates to the distance between the factual $x$ and the counterfactual $x^{\\prime}$. In the context of Algorithmic Recourse, higher distances are typically associated with higher costs to individuals seeking recourse. \n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nusing CounterfactualExplanations.Objectives: distance\nevaluate(ce; measure=distance)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n1-element Vector{Vector{Float32}}:\n [3.6304846]\n```\n:::\n:::\n\n\nBy default, `distance` computes the L2 (Euclidean) distance. \n\n### Multiple Measures, Single Counterfactual\n\nYou might be interested in computing not just the L2 distance, but various LP norms. This can be done by supplying a vector of functions to the `measure` key argument. For convenience, all default distance measures have already been collected in a vector:\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\nusing CounterfactualExplanations.Evaluation: distance_measures\ndistance_measures\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n4-element Vector{Function}:\n distance_l0 (generic function with 1 method)\n distance_l1 (generic function with 1 method)\n distance_l2 (generic function with 1 method)\n distance_linf (generic function with 1 method)\n```\n:::\n:::\n\n\nWe can use this vector of evaluation measures as follows:\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\nevaluate(ce; measure=distance_measures)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n4-element Vector{Vector{Float32}}:\n [2.0]\n [3.6304846]\n [2.9974036]\n [2.9093676]\n```\n:::\n:::\n\n\nIf no `measure` is specified, the `evaluate` method will return all default measures,\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\nevaluate(ce)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n3-element Vector{Vector}:\n [1.0]\n Float32[3.6304846]\n [0.0]\n```\n:::\n:::\n\n\nwhich include:\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code}\nCounterfactualExplanations.Evaluation.default_measures\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n3-element Vector{Function}:\n validity (generic function with 1 method)\n distance (generic function with 1 method)\n redundancy (generic function with 1 method)\n```\n:::\n:::\n\n\n### Multiple Measures and Counterfactuals\n\nWe can also evaluate multiple counterfactual explanations at once:\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\ngenerator = DiCEGenerator()\nces = generate_counterfactual(x, target, counterfactual_data, M, generator; num_counterfactuals=5)\nevaluate(ces)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n3-element Vector{Vector}:\n [1.0]\n Float32[3.5359674]\n [[0.0, 0.0, 0.0, 0.0, 0.0]]\n```\n:::\n:::\n\n\nBy default, each evaluation measure is aggregated across all counterfactual explanations. To return individual measures for each counterfactual explanation you can specify `report_each=true`\n\n::: {.cell execution_count=9}\n``` {.julia .cell-code}\nevaluate(ces; report_each=true)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n3-element Vector{Vector}:\n BitVector[[1, 1, 1, 1, 1]]\n Vector{Float32}[[3.8770418, 3.3639247, 3.653852, 3.310768, 3.4742484]]\n [[0.0, 0.0, 0.0, 0.0, 0.0]]\n```\n:::\n:::\n\n\n## Custom Measures\n\nA `measure` is just a method that takes a `CounterfactualExplanation` as its only positional argument and `agg::Function` as a key argument specifying how measures should be aggregated across counterfactuals. Defining custom measures is therefore straightforward. For example, we could define a measure to compute the inverse target probability as follows:\n\n::: {.cell execution_count=10}\n``` {.julia .cell-code}\nmy_measure(ce::CounterfactualExplanation; agg=mean) = agg(1 .- CounterfactualExplanations.target_probs(ce))\nevaluate(ce; measure=my_measure)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n1-element Vector{Vector{Float32}}:\n [0.22146827]\n```\n:::\n:::\n\n\n## Tidy Output\n\nBy default, `evaluate` returns vectors of evaluation measures. The optional key argument `output_format::Symbol` can be used to post-process the output in two ways: firstly, to return the output as a dictionary, specify `output_format=:Dict`:\n\n::: {.cell execution_count=11}\n``` {.julia .cell-code}\nevaluate(ces; output_format=:Dict, report_each=true)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\nDict{Symbol, Vector} with 3 entries:\n  :validity   => BitVector[[1, 1, 1, 1, 1]]\n  :redundancy => [[0.0, 0.0, 0.0, 0.0, 0.0]]\n  :distance   => Vector{Float32}[[3.87704, 3.36392, 3.65385, 3.31077, 3.47425]]\n```\n:::\n:::\n\n\nSecondly, to return the output as a data frame, specify `output_format=:DataFrame`.\n\n::: {.cell execution_count=12}\n``` {.julia .cell-code}\nevaluate(ces; output_format=:DataFrame, report_each=true)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n\\begin{tabular}{r|ccc}\n\t& num\\_counterfactual & variable & value\\\\\n\t\\hline\n\t& Int64 & String & Float64\\\\\n\t\\hline\n\t1 & 1 & distance & 3.87704 \\\\\n\t2 & 2 & distance & 3.36392 \\\\\n\t3 & 3 & distance & 3.65385 \\\\\n\t4 & 4 & distance & 3.31077 \\\\\n\t5 & 5 & distance & 3.47425 \\\\\n\t6 & 1 & redundancy & 0.0 \\\\\n\t7 & 2 & redundancy & 0.0 \\\\\n\t8 & 3 & redundancy & 0.0 \\\\\n\t9 & 4 & redundancy & 0.0 \\\\\n\t10 & 5 & redundancy & 0.0 \\\\\n\t11 & 1 & validity & 1.0 \\\\\n\t12 & 2 & validity & 1.0 \\\\\n\t13 & 3 & validity & 1.0 \\\\\n\t14 & 4 & validity & 1.0 \\\\\n\t15 & 5 & validity & 1.0 \\\\\n\\end{tabular}\n\n:::\n:::\n\n\nBy default, data frames are pivoted to long format using individual counterfactuals as the `id` column. This behaviour can be suppressed by specifying `pivot_longer=false`.\n\n## Multiple Counterfactual Explanations\n\nIt may be necessary to generate counterfactual explanations for multiple individuals. \n\n::: {.cell execution_count=13}\n\n::: {.cell-output .cell-output-display execution_count=14}\nBelow, for example, we first select multiple samples (5) from the non-target class and then generate counterfactual explanations for all of them. \n\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.julia .cell-code}\n# Factual and target:\nids = rand(findall(predict_label(M, counterfactual_data) .== factual), n_individuals)\nxs = select_factual(counterfactual_data, ids)\nces = generate_counterfactual(xs, target, counterfactual_data, M, generator; num_counterfactuals=5)\nevaluation = evaluate(ces)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n\\begin{tabular}{r|cccc}\n\t& sample & num\\_counterfactual & variable & value\\\\\n\t\\hline\n\t& Int64 & Int64 & String & Any\\\\\n\t\\hline\n\t1 & 1 & 1 & distance & 3.51446 \\\\\n\t2 & 1 & 1 & redundancy & [0.0, 0.0, 0.0, 0.0, 0.0] \\\\\n\t3 & 1 & 1 & validity & 1.0 \\\\\n\t4 & 2 & 1 & distance & 3.15563 \\\\\n\t5 & 2 & 1 & redundancy & [0.0, 0.0, 0.0, 0.0, 0.0] \\\\\n\t6 & 2 & 1 & validity & 1.0 \\\\\n\t7 & 3 & 1 & distance & 3.49398 \\\\\n\t8 & 3 & 1 & redundancy & [0.0, 0.0, 0.0, 0.0, 0.0] \\\\\n\t9 & 3 & 1 & validity & 1.0 \\\\\n\t10 & 4 & 1 & distance & 4.58058 \\\\\n\t11 & 4 & 1 & redundancy & [0.0, 0.0, 0.0, 0.0, 0.0] \\\\\n\t12 & 4 & 1 & validity & 0.8 \\\\\n\t13 & 5 & 1 & distance & 3.66033 \\\\\n\t14 & 5 & 1 & redundancy & [0.0, 0.0, 0.0, 0.0, 0.0] \\\\\n\t15 & 5 & 1 & validity & 0.8 \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n::: {.cell execution_count=15}\n\n::: {.cell-output .cell-output-stdout}\n```\n15×4 DataFrame\n Row │ sample  num_counterfactual  variable    value                     \n     │ Int64   Int64               String      Any                       \n─────┼───────────────────────────────────────────────────────────────────\n   1 │      1                   1  distance    3.51446\n   2 │      1                   1  redundancy  [0.0, 0.0, 0.0, 0.0, 0.0]\n   3 │      1                   1  validity    1.0\n   4 │      2                   1  distance    3.15563\n   5 │      2                   1  redundancy  [0.0, 0.0, 0.0, 0.0, 0.0]\n   6 │      2                   1  validity    1.0\n   7 │      3                   1  distance    3.49398\n   8 │      3                   1  redundancy  [0.0, 0.0, 0.0, 0.0, 0.0]\n   9 │      3                   1  validity    1.0\n  10 │      4                   1  distance    4.58058\n  11 │      4                   1  redundancy  [0.0, 0.0, 0.0, 0.0, 0.0]\n  12 │      4                   1  validity    0.8\n  13 │      5                   1  distance    3.66033\n  14 │      5                   1  redundancy  [0.0, 0.0, 0.0, 0.0, 0.0]\n  15 │      5                   1  validity    0.8\n```\n:::\n:::\n\n\nThis leads us to our next topic: Performance Benchmarks.\n\n",
    "supporting": [
      "evaluation_files"
    ],
    "filters": []
  }
}