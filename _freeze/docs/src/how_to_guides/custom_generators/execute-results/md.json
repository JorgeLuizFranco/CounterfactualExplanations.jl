{
  "hash": "0e536d1de22b9975bf4c356334ce6328",
  "result": {
    "markdown": "```@meta\nCurrentModule = CounterfactualExplanations \n```\n\n\n\n# How to add Custom Generators\n\nAs we will see in this short tutorial, building custom counterfactual generators is straightforward. We hope that this will facilitate contributions through the community.\n\n## Generic generator with dropout\n\nTo illustrate how custom generators can be implemented we will consider a simple example of a generator that extends the functionality of our `GenericGenerator`. We have noted elsewhere that the effectiveness of counterfactual explanations depends to some degree on the quality of the fitted model. Another, perhaps trivial, thing to note is that counterfactual explanations are not unique: there are potentially many valid counterfactual paths. One interesting (or silly) idea following these two observations might be to introduce some form of regularization in the counterfactual search. For example, we could use dropout to randomly switch features on and off in each iteration. Without dwelling further on the usefulness of this idea, let us see how it can be implemented.\n\nThe first code chunk below implements two important steps: 1) create an abstract subtype of the `AbstractGradientBasedGenerator` and 2) create a constructor similar to the `GenericConstructor`, but with one additional field for the probability of dropout.\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\n# Abstract suptype:\nabstract type AbstractDropoutGenerator <: AbstractGradientBasedGenerator end\n\n# Constructor:\nstruct DropoutGenerator <: AbstractDropoutGenerator\n    loss::Union{Nothing,Function} # loss function\n    complexity::Function # complexity function\n    λ::AbstractFloat # strength of penalty\n    decision_threshold::Union{Nothing,AbstractFloat} \n    opt::Any # optimizer\n    τ::AbstractFloat # tolerance for convergence\n    p_dropout::AbstractFloat # dropout rate\nend\n\n# Instantiate:\nusing LinearAlgebra\ngenerator = DropoutGenerator(\n    :logitbinarycrossentropy,\n    norm,\n    0.1,\n    0.5,\n    Flux.Optimise.Descent(0.025),\n    0.1,\n    0.5\n)\n```\n:::\n\n\nNext, we define how feature perturbations are generated for our dropout generator: in particular, we extend the relevant function through a method that implemented the dropout logic.\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nusing CounterfactualExplanations.Generators\nusing StatsBase\nfunction Generators.generate_perturbations(\n    generator::AbstractDropoutGenerator, \n    ce::CounterfactualExplanation\n)\n    s′ = deepcopy(ce.s′)\n    new_s′ = Generators.propose_state(generator, ce)\n    Δs′ = new_s′ - s′ # gradient step\n\n    # Dropout:\n    set_to_zero = sample(\n        1:length(Δs′),\n        Int(round(generator.p_dropout*length(Δs′))),\n        replace=false\n    )\n    Δs′[set_to_zero] .= 0\n    return Δs′\nend\n```\n:::\n\n\nFinally, we proceed to generate counterfactuals in the same way we always do:\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\nce = generate_counterfactual(x, target, counterfactual_data, M, generator)\nplot(ce)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n![](custom_generators_files/figure-commonmark/cell-5-output-1.svg){}\n:::\n:::\n\n\n",
    "supporting": [
      "custom_generators_files"
    ],
    "filters": []
  }
}