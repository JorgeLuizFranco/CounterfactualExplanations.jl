
% JuliaCon proceedings template
\documentclass{juliacon}
\setcounter{page}{1}

\begin{document}

\input{header}

\maketitle

\begin{abstract}

Machine learning models like deep neural networks have become so complex and opaque over recent years that they are generally considered as black boxes. Nonetheless such models play a key role in modern automated decision-making systems. Counterfactual explanations (CE) can help programmers make sense of the systems they build: they explain how inputs into a system need to change for it to produce different decisions. Explanations that involve realistic and actionable changes can be used for the purpose of algorithmic recourse (AR): they offer individuals subject to algorithms a way to turn a negative decision into positive one. In this article we discuss the usefulness of counterfactual explanations for interpretable machine learning and demonstrate its implementation in Julia using the \verb|CounterfactualExplanations| package.

\end{abstract}

\section{Methodology}
\label{sec:methodology}

\section{Using \texttt{CounterfactualExplanations}}
\label{sec:using}

\subsection{Counterfactual generators}
\label{sec:generators}

\subsection{Custom models}
\label{sec:models}

\section{Empirical example}
\label{sec:empirics}

\section{Future and related work}
\label{sec:related}

\cite{wachter2017counterfactual}

\input{bib.tex}

\end{document}

% Inspired by the International Journal of Computer Applications template
