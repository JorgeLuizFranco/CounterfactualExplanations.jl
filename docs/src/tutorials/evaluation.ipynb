{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute: \n",
        "  output: true\n",
        "---"
      ],
      "id": "2b520fe5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```@meta\n",
        "CurrentModule = CounterfactualExplanations \n",
        "```\n"
      ],
      "id": "8f950949"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "include(\"$(pwd())/docs/setup_docs.jl\")\n",
        "eval(setup_docs)"
      ],
      "id": "3e484807",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Performance Evaluation\n",
        "\n",
        "Now that we know how to generate counterfactual explanations in Julia, you may have a few follow-up questions: How do I know if the counterfactual search has been successful? How good is my counterfactual explanation? What does 'good' even mean in this context? In this tutorial, we will see how counterfactual explanations can be evaluated with respect to their performance.\n",
        "\n",
        "## Default Measures\n",
        "\n",
        "Numerous evaluation measures for counterfactual explanations have been proposed. In what follows, we will cover some of the most important measures.\n",
        "\n",
        "### Single Measure, Single Counterfactual\n",
        "\n",
        "One of the most important measures is [`validity`](@ref), which simply determines whether or not a counterfactual explanation $x^{\\prime}$ is valid in the sense that it yields the target prediction: $M(x^{\\prime})=t$. We can evaluate the validity of a single counterfactual explanation `ce` using the [`Evaluation.evaluate`](@ref) function as follows:\n"
      ],
      "id": "2570671a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using CounterfactualExplanations.Evaluation: evaluate, validity\n",
        "evaluate(ce; measure=validity)"
      ],
      "id": "76a71e8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a single counterfactual explanation, this evaluation measure can only take two values: it is either equal to `1`, if the explanation is valid or `0` otherwise. Another important measure is [`distance`](@ref), which relates to the distance between the factual $x$ and the counterfactual $x^{\\prime}$. In the context of Algorithmic Recourse, higher distances are typically associated with higher costs to individuals seeking recourse. \n"
      ],
      "id": "021f96bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using CounterfactualExplanations.Evaluation: distance\n",
        "evaluate(ce; measure=distance)"
      ],
      "id": "df5153c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, `distance` computes the L2 (Euclidean) distance. \n",
        "\n",
        "### Multiple Measures, Single Counterfactual\n",
        "\n",
        "You might be interested in computing not just the L2 distance, but various LP norms. This can be done by supplying a vector of functions to the `measure` key argument. For convenience, all default distance measures have already been collected in a vector:\n"
      ],
      "id": "fe2eb086"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using CounterfactualExplanations.Evaluation: distance_measures\n",
        "distance_measures"
      ],
      "id": "6cc52772",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use this vector of evaluation measures as follows:\n"
      ],
      "id": "dada389b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "evaluate(ce; measure=distance_measures)"
      ],
      "id": "3d0ddc78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If no `measure` is specified, the `evaluate` method will return all default measures,\n"
      ],
      "id": "54378aac"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "evaluate(ce)"
      ],
      "id": "5afd7c99",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "which include:\n"
      ],
      "id": "db4cc74f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "CounterfactualExplanations.Evaluation.default_measures"
      ],
      "id": "ad10b069",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multiple Measures and Counterfactuals\n",
        "\n",
        "We can also evaluate multiple counterfactual explanations at once:\n"
      ],
      "id": "16fb049d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "generator = DiCEGenerator()\n",
        "ces = generate_counterfactual(x, target, counterfactual_data, M, generator; num_counterfactuals=5)\n",
        "evaluate(ces)"
      ],
      "id": "19f895f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, each evaluation measure is aggregated across all counterfactual explanations. To return individual measures for each counterfactual explanation you can specify `report_each=true`\n"
      ],
      "id": "149e243d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "evaluate(ces; report_each=true)"
      ],
      "id": "bfe75f70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Measures\n",
        "\n",
        "A `measure` is just a method that takes a `CounterfactualExplanation` as its only positional argument and `agg::Function` as a key argument specifying how measures should be aggregated across counterfactuals. Defining custom measures is therefore straightforward. For example, we could define a measure to compute the inverse target probability as follows:\n"
      ],
      "id": "3cc2db29"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_measure(ce::CounterfactualExplanation; agg=mean) = agg(1 .- CounterfactualExplanations.target_probs(ce))\n",
        "evaluate(ce; measure=my_measure)"
      ],
      "id": "a6b45c3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tidy Output\n",
        "\n",
        "By default, `evaluate` returns vectors of evaluation measures. The optional key argument `output_format::Symbol` can be used to post-process the output in two ways: firstly, to return the output as a dictionary, specify `output_format=:Dict`:\n"
      ],
      "id": "2b023d7c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "evaluate(ces; output_format=:Dict, report_each=true)"
      ],
      "id": "9fec531a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Secondly, to return the output as a data frame, specify `output_format=:DataFrame`.\n"
      ],
      "id": "e5468321"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "evaluate(ces; output_format=:DataFrame, report_each=true)"
      ],
      "id": "32e9e2f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, data frames are pivoted to long format using individual counterfactuals as the `id` column. This behaviour can be suppressed by specifying `pivot_longer=false`.\n",
        "\n",
        "## Multiple Counterfactual Explanations\n",
        "\n",
        "It may be necessary to generate counterfactual explanations for multiple individuals. \n"
      ],
      "id": "88e3dda3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "n_individuals = 5\n",
        "Markdown.parse(\n",
        "    \"\"\"\n",
        "    Below, for example, we first select multiple samples ($n_individuals) from the non-target class and then generate counterfactual explanations for all of them. \n",
        "    \"\"\"\n",
        ")"
      ],
      "id": "089d69c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Factual and target:\n",
        "ids = rand(findall(predict_label(M, counterfactual_data) .== factual), n_individuals)\n",
        "xs = select_factual(counterfactual_data, ids)\n",
        "ces = generate_counterfactual(xs, target, counterfactual_data, M, generator; num_counterfactuals=5)\n",
        "evaluation = evaluate(ces)"
      ],
      "id": "bfcb50de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "show(evaluation)"
      ],
      "id": "6d797f00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This leads us to our next topic: Performance Benchmarks."
      ],
      "id": "9ebdae36"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.9",
      "language": "julia",
      "display_name": "Julia 1.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}