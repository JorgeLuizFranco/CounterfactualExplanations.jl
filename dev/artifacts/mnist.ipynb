{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"generate_artifacts.jl\")\n",
    "include(\"../utils.jl\")\n",
    "data_dir = \"../data\"\n",
    "artifact_name = \"mnist\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, MLDatasets\n",
    "using MLDatasets.MNIST: convert2image\n",
    "using BSON\n",
    "using BSON: @save, @load\n",
    "train_x, train_y = MNIST.traindata()\n",
    "train_x = Float32.(train_x)\n",
    "train_y = Float32.(train_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehotbatch, onecold, DataLoader\n",
    "y = Flux.onehotbatch(train_y, 0:9)\n",
    "x = Flux.flatten(train_x)\n",
    "bs = Int(round(size(x)[2]/10))\n",
    "data_train = DataLoader((x,y),batchsize=bs)\n",
    "data = Dict(\n",
    "    \"data\" => DataLoader((x,y),batchsize=bs),\n",
    "    \"x\" => x,\n",
    "    \"y\" => y\n",
    ")\n",
    "@save joinpath(data_dir, artifact_name * \"_data.bson\") data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_train\n",
    "output_dim = 10\n",
    "input_dim = prod(size(train_x[:,:,1]))\n",
    "hidden_dim = 32\n",
    "kw_args = (input_dim=input_dim,n_hidden=hidden_dim,output_dim=output_dim,batch_norm=true)\n",
    "model = build_model(;kw_args...)\n",
    "loss(x, y) = Flux.Losses.logitcrossentropy(model(x), y)\n",
    "\n",
    "using Flux.Optimise: update!, ADAM\n",
    "using Statistics\n",
    "opt = ADAM()\n",
    "epochs = 10\n",
    "avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n",
    "accuracy(data) = mean(map(d -> mean(onecold(softmax(model(d[1])), 0:9) .== onecold(d[2], 0:9)), data))\n",
    "\n",
    "if false\n",
    "  for epoch = 1:epochs\n",
    "    for d in data\n",
    "      gs = gradient(params(model)) do\n",
    "        l = loss(d...)\n",
    "      end\n",
    "      update!(opt, params(model), gs)\n",
    "    end\n",
    "    @info \"Epoch \" * string(epoch)\n",
    "    @show accuracy(data)\n",
    "  end\n",
    "  @save joinpath(data_dir, artifact_name * \"_model.bson\") model\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "𝓜 = build_ensemble(5;kw=kw_args)\n",
    "if false\n",
    "    𝓜, anim = forward(𝓜, data, opt, n_epochs=epochs, plot_loss=false) # fit the ensemble\n",
    "    save_ensemble(𝓜;root=joinpath(data_dir, artifact_name * \"_ensemble\")) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: For automatic github deployment, need GITHUB_TOKEN. Not found in ENV, attemptimg global git config.\n",
      "└ @ Main /Users/FA31DU/Documents/code/CounterfactualExplanations.jl/dev/artifacts/generate_artifacts.jl:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Binding mnist_data in Artifacts.toml...\n",
      "└ @ Main /Users/FA31DU/Documents/code/CounterfactualExplanations.jl/dev/artifacts/generate_artifacts.jl:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Binding mnist_model in Artifacts.toml...\n",
      "└ @ Main /Users/FA31DU/Documents/code/CounterfactualExplanations.jl/dev/artifacts/generate_artifacts.jl:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Binding mnist_ensemble in Artifacts.toml...\n",
      "└ @ Main /Users/FA31DU/Documents/code/CounterfactualExplanations.jl/dev/artifacts/generate_artifacts.jl:53\n",
      "┌ Info: Uploading tarballs to pat-alt/CounterfactualExplanations.jl tag `data`\n",
      "└ @ Main /Users/FA31DU/Documents/code/CounterfactualExplanations.jl/dev/artifacts/generate_artifacts.jl:64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: found release (data). Use existing one.\n",
      "--> Deleting: mnist_model.tar.gz\n",
      "--> Deleting: mnist_ensemble.tar.gz\n",
      "--> Deleting: mnist_data.tar.gz\n",
      "--> Uploading: mnist_data.tar.gz\n",
      "--> Uploading: mnist_ensemble.tar.gz\n",
      "--> Uploading: mnist_model.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Artifacts.toml file now contains all bound artifact names\n",
      "└ @ Main /Users/FA31DU/Documents/code/CounterfactualExplanations.jl/dev/artifacts/generate_artifacts.jl:70\n"
     ]
    }
   ],
   "source": [
    "datafiles = [artifact_name * \"_data.bson\",artifact_name * \"_model.bson\",artifact_name * \"_ensemble\"]\n",
    "generate_artifact(datafiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.4",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
