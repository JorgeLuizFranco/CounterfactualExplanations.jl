---
jupyter: julia-1.7
---

```{julia}
using Pkg; Pkg.activate("dev")
include("dev/artifacts/generate_artifacts.jl")
include("dev/utils.jl")
data_dir = "dev/artifacts/data"
artifact_name = "synthetic"
using BSON
using BSON: @save, @load
```

## Set up

A container for the training data:

```{julia}
data_dict = Dict()
```

A container for Flux models:

```{julia}
flux_models = Dict()
```

Separate folder for R models:

```{julia}
r_files = artifact_name * "_r_torch"
r_model_dir = joinpath(data_dir, r_files)
if !isdir(r_model_dir)
    mkdir(r_model_dir)
end
```


## Binary Classification

```{julia}
using Random
# Some random data:
Random.seed!(1234);
N = 100
using CounterfactualExplanations
using CounterfactualExplanations.Data
xs, ys = Data.toy_data_non_linear(N)
X = hcat(xs...)
counterfactual_data = CounterfactualData(X,ys')
```

### Flux

```{julia}
nn = build_model(activation=Flux.Ïƒ)
loss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y)
ps = Flux.params(nn)
data = zip(xs,ys)
data_dict[:classification_binary] = data
```

```{julia}
using Flux.Optimise: update!, ADAM
opt = ADAM(0.1)
epochs = 100
avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))
show_every = epochs/10

for epoch = 1:epochs
  for d in data
    gs = gradient(Flux.params(nn)) do
      l = loss(d...)
    end
    update!(opt, Flux.params(nn), gs)
  end
  if epoch % show_every == 0
    println("Epoch " * string(epoch))
    @show avg_loss(data)
  end
end
```

```{julia}
flux_models[:classification_binary] = Dict(
  :raw_model => nn
)
```

### R `torch`

```{julia}
using RCall
R"""
library(torch)
X <- torch_tensor(t($X))
ys <- torch_tensor($ys)
torch_save(X,"dev/artifacts/R/classification_binary/X.pt")
torch_save(ys,"dev/artifacts/R/classification_binary/ys.pt")
source("dev/artifacts/R/classification_binary/model.R")
run_model($r_model_dir)
"""
```

## Multi-class

```{julia}
using CounterfactualExplanations.Data
xs, ys = Data.toy_data_multi()
X = hcat(xs...)
y_train = Flux.onehotbatch(ys, unique(ys))
y_train = Flux.unstack(y_train',1)
```

### Flux

```{julia}
n_hidden = 32
out_dim = length(unique(ys))
kw = (output_dim=out_dim, dropout=true)
nn = build_model(;kw...)
loss(x, y) = Flux.Losses.logitcrossentropy(nn(x), y)
ps = Flux.params(nn)
data = zip(xs,y_train)
data_dict[:classification_multi] = data
```

```{julia}
using Flux.Optimise: update!, ADAM
opt = ADAM()
epochs = 10
avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))
show_every = epochs/10

for epoch = 1:epochs
  for d in data
    gs = gradient(Flux.params(nn)) do
      l = loss(d...)
    end
    update!(opt, Flux.params(nn), gs)
  end
  if epoch % show_every == 0
    println("Epoch " * string(epoch))
    @show avg_loss(data)
  end
end
```

```{julia}
flux_models[:classification_multi] = Dict(
  :raw_model => nn
)
```

### R `torch`

```{julia}
using RCall
R"""
library(torch)
X <- torch_tensor(t($X))
ys <- torch_tensor($ys, dtype=torch_int64())
torch_save(X,"dev/artifacts/R/classification_multi/X.pt")
torch_save(ys,"dev/artifacts/R/classification_multi/ys.pt")
source("dev/artifacts/R/classification_multi/model.R")
run_model($r_model_dir)
"""
```

## Save and Push

```{julia}
# Data
@save joinpath(data_dir, artifact_name * "_data.bson") data_dict
data_files = artifact_name * "_data.bson"

# Flux
@save joinpath(data_dir, artifact_name * "_flux.bson") flux_models
flux_files = artifact_name * "_flux.bson"

# R torch
datafiles = [data_files, flux_files, r_files]

generate_artifact(datafiles)
```




